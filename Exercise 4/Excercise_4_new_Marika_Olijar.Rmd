---
title: "Exercise_4_811"
author: "Marika Olijar"
date: "10/15/2021"
output:
  pdf_document: default
  html_document: default
---
Download the food_coded.csv file2. Load the CSV file into your R environment.
Open the codebook_food.docx file for guidance.

3. Extract the first 95 rows.
```{r setup, include =FALSE}
options(knitr.duplicate.label = "allow")
knitr::opts_chunk$set(echo = TRUE)
food_coded <- read.csv("food_coded.csv")
food_95 <- food_coded[1:95,]
```

4. Look at the following variables using both name and column index/number:
GPA
calories_chicken
drink
fav_cuisine
father_profession
mother_profession
```{r}
colnames(food_coded)
food_index <- food_coded[,c(1,4,16,26,25,45)]
head(food_index)
```
New variable for how healthy each person feels but convert the scale from 1 to 10 to 1 to 100
```{r}
food_coded$healthy_feeling
food_coded.new <- food_coded
food_coded.new$health_feel_scaled <- (food_coded$healthy_feeling*10)
food_coded.new$health_feel_scaled
```

6 Filter to students who are female and have GPAs that are above 3

```{r}
gpa_female <- food_coded[food_coded$Gender=="1" & food_coded$GPA > 3.0,]
head(gpa_female)
```


7 Find the mean and standard deviation for the following variables, and summarize them in a data frame:
chicken_calories • tortilla_calories • turkey_calories • waffle_calories
```{r}
food_calories <- food_coded[,c(4, 54, 55, 60)]
?sapply
m <- sapply(food_calories, mean, na.rm = T)
sd <- sapply(food_calories, sd, na.rm = T)
calories_m_sd <- rbind(m, sd)
head(calories_m_sd)
```

8. Summarize GPA and weight within the gender and cuisine variables.
```{r}
class(food_coded$weight)
food_coded$weight <- as.numeric(food_coded$weight)
food_coded$GPA <- as.numeric(food_coded$GPA)

food_men <- food_coded[food_coded$Gender == 2,]
food_women <- food_coded[food_coded$Gender == 1,]

gpa_mean_men <- tapply(food_men$GPA, food_men$cuisine, mean, na.rm = T)
gpa_sd_men <- tapply(food_men$GPA, food_men$cuisine, sd, na.rm = T)

gpa_mean_women <- tapply(food_women$GPA, food_women$cuisine, mean, na.rm = T)
gpa_sd_women <- tapply(food_women$GPA, food_women$cuisine, sd, na.rm = T)

weight_mean_men <- tapply(food_men$weight, food_men$cuisine, mean, na.rm = T)
weight_sd_men <- tapply(food_men$weight, food_men$cuisine, sd, na.rm = T)

weight_mean_women <- tapply(food_women$weight, food_women$cuisine, mean, na.rm = T)
weight_sd_women <- tapply(food_women$weight, food_women$cuisine, sd, na.rm = T)
```

1. Download the facebook-fact-check.csv
2. Load the CSV file into your R environment.
```{r}
fb_fact <- read.csv("facebook-fact-check.csv")
library(dplyr)
```
3. Extract the last 500 rows.

Hint: Check out the top_n() page to figure out how to extract the last 500 rows instead of the first 500 rows.
```{r}
fb_extract <- fb_fact %>% slice_tail(n = 500)
head(fb_extract)
```
* top_n() is superceded so I tried something else!

4. Look at the even-numbered column indices only. Identify them by name.
```{r}
row_odd <- seq_len(nrow(fb_extract)) %% 2 
data_row_odd <- fb_extract[row_odd == 1, ]
colnames(data_row_odd)
```


5. Using mutate, create a new variable called post_type_coded that renames each post type to the following:
• link=1 • photo = 2 • text=3 • video = 4
Hint: look up case_when within tidyverse. You can also use if_else
```{r}
fb_extract <- fb_extract %>% 
  mutate(post_type_coded = ifelse(Post.Type == "link", '1', 
                                  ifelse(Post.Type == 'photo', '2', 
                                         ifelse(Post.Type == 'text', '3','4'))))
```


6. Arrange page names in reverse order.
```{r}
fb_extract <- fb_extract %>% arrange(desc(Page))
head(fb_extract)
```

7. Find the mean and standard deviation for the following variables, and summarize them.
• share_count
• reaction_count 
• comment_count
```{r}
fb_fact %>% 
  summarise(share_count = mean(share_count, na.rm=T),
            reaction_count = mean(reaction_count, na.rm=T),
            comment_count = mean(comment_count, na.rm=T))
```

8. Summarize the mean and standard deviations in Question 7 with the “mainstream” values in the category variable.
```{r}
fb_main <- fb_fact %>% 
  filter(Category == "mainstream") %>% 
  summarize(share_count_m = mean(share_count, na.rm=T), #creating 6 variables
            reaction_count_m = mean(reaction_count, na.rm=T),
            comment_count_m = mean(comment_count, na.rm=T),
            share_count_sd = sd(share_count, na.rm=T),
            reaction_count_sd = sd(reaction_count, na.rm=T),
            comment_count_sd = sd(comment_count, na.rm=T))
```

Submit
Email me (laaker@wisc.edu) the link to your ps811-exercises repository when you are done.




